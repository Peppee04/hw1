{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **HOMEWORK 1 - Regressione Lineare**\n\nIn questo homework dovrete:\n\n1. Scrivere una funzione di pipeline che deve gestire l' allenamento di un modello di regressione lineare al variare degli iperparametri forniti. Nello specifico:\n    * Deve applicare la PCA, se presente.\n    \n    * Deve applicare la standardizzazione, se presente.\n\n    * Deve applicare la regolarizzazione, se presente.\n\n    * Deve allenare il modello di regressione lineare.\n\n    * Deve calcolare la MAE.\n\n2. Scrivere una funzione che utilizzi la `pipeline` definita al punto 1 e che testi tutte le configurazioni possibili presenti in `configs`. Nel dettaglio la funzione deve:\n    * Dividere il dataset in train e validation.\n\n    * Calcolare, grazie alla funzione `pipeline` definita al punto 1, quale configurazione ottiene il punteggio migliore (quale configurazione ha la MAE di validation più bassa).\n\n3. Scrivere una funzione che utilizzi la configurazione migliore prodotta dalla funzione definita al punto 2 e la testi sul test set. \n\n4. Stampare:\n    * La migliore configurazione\n\n    * Il miglior MAE di validation \n\n    * Il migliore MAE di train\n\n    * Il MAE di test \n\n\nIl codice che di seguito trovate già fornito deve essere utilizzato per la risoluzione dell' homework, **NON MODIFICATELO IN ALCUN MODO**.","metadata":{}},{"cell_type":"markdown","source":"## **Dataset Wine Quality White**\n\nIl dataset da utilizzare è `wine-quality-white` della libreria `scikit-learn`. Il dataset contiene 11 variabili numeriche + 1 di target che classifica il vino in diverse categorie di qualità. Per il nostro obiettivo la variabile di target è considerata come `float`, permettendoci di applicare la regressione lineare. All' interno del dataset sono contenuti 4898 campioni. ","metadata":{}},{"cell_type":"code","source":"# Questa cella contiene tutte le librerie di cui necessitate per risolvere l' homework.\n# Ricordate di eseguirla prima di iniziare.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T10:33:15.238066Z","iopub.execute_input":"2025-04-13T10:33:15.238456Z","iopub.status.idle":"2025-04-13T10:33:15.243463Z","shell.execute_reply.started":"2025-04-13T10:33:15.238431Z","shell.execute_reply":"2025-04-13T10:33:15.242311Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"hyperparams = {\n    # PCA\n    'use_pca': [True, False],\n    'pca_standardize': [True, False],\n    'pca_components': [3, 5, 10],\n    # Data standardization\n    'data_standardize': [True, False],\n    # Regularization l2\n    'use_regularization': [True, False],\n    'reg_lambda': [0.1, 1, 10],\n}\n\n# Calcoliamo tutte le possibili combinazioni di iperparametri\nimport itertools\ncombinations = list(itertools.product(*hyperparams.values()))\nconfigs = [dict(zip(hyperparams.keys(), combination)) for combination in combinations]\n\n# Evitiamo le combinazioni non valide\nfor config in configs:\n    if not config['use_pca']:\n        config['pca_standardize'] = None\n        config['pca_components'] = None\n    if not config['use_regularization']:\n        config['reg_lambda'] = None\nconfigs = set([tuple(config.items()) for config in configs])\n\n# Convertiamo di nuovo in lista di dizionari\nconfigs = [dict(config) for config in configs]\nprint(f'Numero di combinazioni: {len(configs)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T10:34:38.691512Z","iopub.execute_input":"2025-04-13T10:34:38.691824Z","iopub.status.idle":"2025-04-13T10:34:38.700335Z","shell.execute_reply.started":"2025-04-13T10:34:38.691802Z","shell.execute_reply":"2025-04-13T10:34:38.699314Z"}},"outputs":[{"name":"stdout","text":"Numero di combinazioni: 56\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"In `configs` avete una lista di dizionari, ogni dizionario contiene una possibile combinazione di hyperparametri da utilizzare nella fase di training. ","metadata":{}},{"cell_type":"code","source":"# Carica il dataset Wine Quality White\ndata = fetch_openml(name='wine-quality-white', version=1, as_frame=True)\nX = data.data\ny = data.target.astype(float)  # Assicura che il target sia float per la regressione\n\n#1-----------------\ndef pipeline(X_train, y_train, X_val, y_val, hyperparams):\n    \"\"\"\n    Addestra un modello di regressione lineare con eventuale PCA e regolarizzazione L2.\n    \"\"\"\n    if hyperparams['use_pca']:\n        # ...\n        if hyperparams['pca_standardize']: \n            #standardizzo\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_val = scaler.transform(X_val)\n\n        #applico pca\n        n_components = hyperparams['pca_components']\n        pca = PCA(n_components)\n        X_train = pca.fit_transform(X_train)\n        X_val = pca.transform(X_val)\n\n    if hyperparams['data_standardize']:\n        # standardizzo\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_val = scaler.transform(X_val)\n    # Aggiunge il termine costante ai dati\n    X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n    X_val = np.c_[np.ones(X_val.shape[0]), X_val]\n    # Calcolo della soluzione di regressione lineare\n    parametri = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train\n        \n    if hyperparams['use_regularization']:\n        # regolarizzo\n        lamda=hyperparams['reg_lambda']\n        I=np.identity(X_train.shape[1]) #matrice identitá\n        \n        parametri = np.linalg.inv( (X_train.T @ X_train) + lamda * I) @ X_train.T @ y_train\n    else:\n        parametri = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train\n        \n\n    # Calcolo predizioni\n    train_prediction = X_train @ parametri\n    val_prediction = X_val @ parametri\n    # Calcola il MAE\n    mae_train = np.mean(np.abs(train_prediction - y_train))\n    mae_val = np.mean(np.abs(val_prediction- y_val))\n    \n    return mae_train, mae_val\n\n#2------------------\n\"\"\"Nel notebook c'é scritto di creare una funzione, nel sito no, sto seguendo le indicazione del notebook\"\"\"\ndef try_pipeline(X, y, hyperparams):\n    # Dividi il dataset in training e test set\n    # ...\n    train_fraction = 0.8  #assumo divisione 80/20\n    #test_fraction = 0.2 giusto per esplicitare il fatto che sia 0.2\n\n    num_train = int(train_fraction * X.shape[0])\n\n    X_train_val = X[:num_train]\n    y_train_val = y[:num_train]\n\n    X_test = X[num_train:]\n    y_test = y[num_train:]\n    print(\"Divisione generale, train(train+validation) e test: \",X_train_val.shape, X_test.shape)\n    \n    \n\n    # Dividi il training set in training set effettivo e validation set\n    # ...\n    #anche qui assumo divisione 80/20\n    #val_fraction = 0.2 anche qui per esplicitare come sto suddividendo i set\n    num_train = int(train_fraction * X_train_val.shape[0])\n\n    X_train = X_train_val[:num_train]  \n    y_train = y_train_val[:num_train]\n\n    X_val = X_train_val[num_train:] \n    y_val = y_train_val[num_train:]\n    #stampe di controllo, vedo se sto suddividendo per bene i vari set\n    print(\"Shape del training set effettivo: \",X_train.shape)\n    print(\"Shape del validation set effettivo: \",X_val.shape)\n    print(\"Shape del test set effettivo: \",X_test.shape)\n\n    print(\"Controllo che la somma mi dia l'intero X del dataset che deve essere 4898:\",(X_test.shape[0]+X_train.shape[0]+X_val.shape[0]))\n    \n    # Trova la configurazione di iperparametri migliore\n    top_mae_val=float(10000)    #inizializzazione ad un valore alto cosi sono sicuro che venga trovato un mae inferiore\n    top_mae_train=0  \n    top_config=  None  \n    print(\"\\n\\nCERCO MIGLIORE CONFIGURAZIONE IPERPARAMETRI:\")\n    for config in hyperparams: #itero per ogni configurazione\n        print(\"Provo configurazione :\",config)\n\n        #creo copia dei dati per ogni configurazione, sfrutto copy() da voi suggerito nell'homework \n        X_train_copy = X_train.copy()\n        X_val_copy = X_val.copy()\n\n        #richiamo la funzione pipeline\n        mae_train, mae_val = pipeline(X_train_copy, y_train, X_val_copy, y_val, config)\n        print(\"MAE di Train: \",mae_train)\n        print(\"MAE di Val:\",mae_val)\n\n        #salvo il miglior mae tra le diverse configurazioni (mae minimo)\n        if mae_val < top_mae_val:\n            top_mae_val = mae_val\n            top_mae_train = mae_train\n            top_config = config\n\n    print(\"\\n\\n--------Migliore configurazione trovata---------\")\n    print(top_config)\n\n    return top_config, top_mae_train, top_mae_val\n\n#3----------------\ndef pipeline_best_mae(X, y, hyperparams):\n    # suddivido il dataset in training e test set\n    train_fraction = 0.8\n    num_train = int(train_fraction * X.shape[0])\n\n    X_train = X[:num_train]\n    y_train = y[:num_train]\n\n    X_test = X[num_train:]\n    y_test = y[num_train:]\n\n    # Riallena il modello sul training set completo \n    top_config = None\n    top_config, top_mae_train, top_mae_val = try_pipeline(X, y, hyperparams)\n    # Calcola il MAE sul test set\n    mae_train, mae_test = pipeline(X_train, y_train, X_test, y_test, top_config) \n    \n\n    return top_config, top_mae_train, top_mae_val, mae_test\n\n\n#chiamo la funzione per vedere cosa succede: \nconfig,mae_train,mae_val,mae_test=pipeline_best_mae(X,y,configs)\n\n# Stampa  risultati\nprint(\"\\n\\n---Visualizzazione risultati---\")\nprint(\"Migliore configurazione:\",config)\nprint(\"Migliore MAE Train: \",mae_train)\nprint(\"Migliore MAE Validation :\", mae_val)\nprint(\"Migliore MAE Test :\", mae_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T11:35:24.007920Z","iopub.execute_input":"2025-04-13T11:35:24.008289Z","iopub.status.idle":"2025-04-13T11:35:24.750244Z","shell.execute_reply.started":"2025-04-13T11:35:24.008264Z","shell.execute_reply":"2025-04-13T11:35:24.749441Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"Divisione generale, train(train+validation) e test:  (3918, 11) (980, 11)\nShape del training set effettivo:  (3134, 11)\nShape del validation set effettivo:  (784, 11)\nShape del test set effettivo:  (980, 11)\nControllo che la somma mi dia l'intero X del dataset che deve essere 4898: 4898\n\n\nCERCO MIGLIORE CONFIGURAZIONE IPERPARAMETRI:\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 10, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6042864153812809\nMAE di Val: 0.5751931589348114\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 5, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6327575089904057\nMAE di Val: 0.6053428381901863\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 3, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6913086328858924\nMAE di Val: 0.6576692044837218\nProvo configurazione : {'use_pca': False, 'pca_standardize': None, 'pca_components': None, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.5995811665801081\nMAE di Val: 0.5767917859513666\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 3, 'data_standardize': True, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6912996994438666\nMAE di Val: 0.6576547812331368\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 3, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6530127072529298\nMAE di Val: 0.6372267379759691\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': False, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6060289033176675\nMAE di Val: 0.57366332694744\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 5, 'data_standardize': False, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6437946531482529\nMAE di Val: 0.6122602649455559\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6060283810902577\nMAE di Val: 0.5736396509104827\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 5, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6437924168784651\nMAE di Val: 0.6122676714574823\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 3, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6529674339998771\nMAE di Val: 0.637327257815941\nProvo configurazione : {'use_pca': False, 'pca_standardize': None, 'pca_components': None, 'data_standardize': True, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.5995791338399354\nMAE di Val: 0.5768200226377324\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 10, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6043921310686992\nMAE di Val: 0.5730049253763166\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': True, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6060289033176676\nMAE di Val: 0.57366332694744\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 5, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6327495715185424\nMAE di Val: 0.6055261940158233\nProvo configurazione : {'use_pca': False, 'pca_standardize': None, 'pca_components': None, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6092486546256037\nMAE di Val: 0.5789304055225065\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 5, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6327556284636696\nMAE di Val: 0.605353232307953\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6088074083031424\nMAE di Val: 0.5768472551371584\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 3, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6922801266361363\nMAE di Val: 0.6592936835403478\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 3, 'data_standardize': False, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6530178157937584\nMAE di Val: 0.6372156057291026\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 5, 'data_standardize': True, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6327488897516638\nMAE di Val: 0.6055465733859458\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 3, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6530126277295152\nMAE di Val: 0.6372267741440362\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 5, 'data_standardize': True, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6437946531482529\nMAE di Val: 0.6122602649455557\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 10, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6042897556943679\nMAE di Val: 0.5749841965629897\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 5, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6327493793602813\nMAE di Val: 0.605527233718876\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 5, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6436307467914633\nMAE di Val: 0.6131124864440528\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 10, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6043817772396395\nMAE di Val: 0.5730065241180367\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 3, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6922572695921922\nMAE di Val: 0.659217689708026\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 3, 'data_standardize': True, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6530178157937583\nMAE di Val: 0.6372156057291026\nProvo configurazione : {'use_pca': False, 'pca_standardize': None, 'pca_components': None, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.5998509325846053\nMAE di Val: 0.5740752683551011\nProvo configurazione : {'use_pca': False, 'pca_standardize': None, 'pca_components': None, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6062823351892807\nMAE di Val: 0.5744515751744778\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 3, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6525796238201371\nMAE di Val: 0.6384827802671664\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 3, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6913919376381732\nMAE di Val: 0.6578076820037835\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6062655648421565\nMAE di Val: 0.574185310307088\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 10, 'data_standardize': False, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6042862459087842\nMAE di Val: 0.5752163147536816\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 5, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.643618950239679\nMAE di Val: 0.6131014569810528\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6061245872009969\nMAE di Val: 0.5714080179441893\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 10, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6042865069459\nMAE di Val: 0.5751930959930137\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 5, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6328624242685912\nMAE di Val: 0.6035150535427738\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 5, 'data_standardize': False, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6327488897516637\nMAE di Val: 0.6055465733859459\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 10, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6042886346353137\nMAE di Val: 0.5749848230411292\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 3, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6913890082178284\nMAE di Val: 0.6577989723324444\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 5, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6437743946811603\nMAE di Val: 0.6123360574651144\nProvo configurazione : {'use_pca': False, 'pca_standardize': None, 'pca_components': None, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6059380654545684\nMAE di Val: 0.5737295673119689\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 3, 'data_standardize': False, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6912996994438666\nMAE di Val: 0.6576547812331368\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 3, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6913089259123405\nMAE di Val: 0.6576700757072464\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 3, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6529681785135822\nMAE di Val: 0.637326896107423\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6060485051206003\nMAE di Val: 0.5737331126181522\nProvo configurazione : {'use_pca': False, 'pca_standardize': None, 'pca_components': None, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.5996003358730073\nMAE di Val: 0.5765381844872931\nProvo configurazione : {'use_pca': False, 'pca_standardize': None, 'pca_components': None, 'data_standardize': False, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.5995791338549425\nMAE di Val: 0.5768200228148206\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 3, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6525739936236905\nMAE di Val: 0.6385000798990039\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 5, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6437730048403739\nMAE di Val: 0.6123343259502416\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 1}\nMAE di Train:  0.6060251087835576\nMAE di Val: 0.5734288724006079\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 10, 'data_standardize': True, 'use_regularization': False, 'reg_lambda': None}\nMAE di Train:  0.6042862459087842\nMAE di Val: 0.5752163147536816\nProvo configurazione : {'use_pca': True, 'pca_standardize': False, 'pca_components': 5, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 10}\nMAE di Train:  0.6328430966911549\nMAE di Val: 0.603618704341107\nProvo configurazione : {'use_pca': True, 'pca_standardize': True, 'pca_components': 5, 'data_standardize': False, 'use_regularization': True, 'reg_lambda': 0.1}\nMAE di Train:  0.6437925578864657\nMAE di Val: 0.6122678464012408\n\n\n--------Migliore configurazione trovata---------\n{'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 10}\n\n\n---Visualizzazione risultati---\nMigliore configurazione: {'use_pca': True, 'pca_standardize': False, 'pca_components': 10, 'data_standardize': True, 'use_regularization': True, 'reg_lambda': 10}\nMigliore MAE Train:  0.6061245872009969\nMigliore MAE Validation : 0.5714080179441893\nMigliore MAE Test : 0.5456079524655569\n","output_type":"stream"}],"execution_count":41}]}